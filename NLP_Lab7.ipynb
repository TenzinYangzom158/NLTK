{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Lab7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8c7w5747gQIK+Bvq9FNhU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TenzinYangzom158/NLTK/blob/main/NLP_Lab7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Program 7:Write a program for lemmatizing words Using WordNet\n",
        "---\n",
        "Lemmatization is the process of converting a word to its base form."
      ],
      "metadata": {
        "id": "8mTH7PL-5CFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wordnet Lemmatizer with NLTK"
      ],
      "metadata": {
        "id": "AFJJHBt45sH0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pgut8bv4nQX",
        "outputId": "a6fba49d-fb44-4863-89c1-67b585c1bc07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Init the Wordnet Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize Single Word\n",
        "print(\"women: \",lemmatizer.lemmatize(\"women\"))\n",
        "#> woman\n",
        "\n",
        "print(\"shops: \",lemmatizer.lemmatize(\"shops\"))\n",
        "#> shop\n",
        "\n",
        "print(\"are: \",lemmatizer.lemmatize(\"are\"))\n",
        "#> are\n",
        "\n",
        "\n",
        "# Lemmatize Single Word with POS tagging (Part of Speech tagging)\n",
        "print(\"----------\")\n",
        "print(\"women: \",lemmatizer.lemmatize(\"women\" , 'n'))\n",
        "#> woman\n",
        "\n",
        "print(\"shops: \",lemmatizer.lemmatize(\"shops\", 'a'))\n",
        "#> shop\n",
        "\n",
        "print(\"are: \",lemmatizer.lemmatize(\"are\", 'v'))\n",
        "#> are"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRYXA5FG6Qg0",
        "outputId": "5124bb79-32bb-455a-bf58-515bb9bca97f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "women:  woman\n",
            "shops:  shop\n",
            "are:  are\n",
            "----------\n",
            "women:  woman\n",
            "shops:  shops\n",
            "are:  be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sentence to be lemmatized\n",
        "sentence = '''Lemmatization considers the context and converts the word to its meaningful base form, \n",
        "whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors.'''\n",
        "\n",
        "# Tokenize: Split the sentence into words\n",
        "word_list = nltk.word_tokenize(sentence)\n",
        "print(word_list)\n",
        "\n",
        "# Lemmatize list of words and join\n",
        "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
        "print(lemmatized_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSHuX7pB6cx2",
        "outputId": "dc30b77f-84a3-4498-ef9f-52b2f0cbe404"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Lemmatization', 'considers', 'the', 'context', 'and', 'converts', 'the', 'word', 'to', 'its', 'meaningful', 'base', 'form', ',', 'whereas', 'stemming', 'just', 'removes', 'the', 'last', 'few', 'characters', ',', 'often', 'leading', 'to', 'incorrect', 'meanings', 'and', 'spelling', 'errors', '.']\n",
            "Lemmatization considers the context and convert the word to it meaningful base form , whereas stemming just remove the last few character , often leading to incorrect meaning and spelling error .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part-of-speech constants\n",
        "### ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'\n",
        "# POS_LIST = [NOUN, VERB, ADJ, ADV]"
      ],
      "metadata": {
        "id": "DkAlS2Yy_eNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatize with POS Tag\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    # \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "\n",
        "# 1. Init Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# 2. Lemmatize Single Word with the appropriate POS tag\n",
        "word = 'feet'\n",
        "print(lemmatizer.lemmatize(word, get_wordnet_pos(word)))\n",
        "\n",
        "# 3. Lemmatize a Sentence with the appropriate POS tag\n",
        "sentence = \"The striped bats are hanging on their feet for best\"\n",
        "print([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)])\n",
        "#> ['The', 'strip', 'bat', 'be', 'hang', 'on', 'their', 'foot', 'for', 'best']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uysfuzP_642D",
        "outputId": "fba0c291-7fc4-4e5d-ceb5-2418b09cc51e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "foot\n",
            "['The', 'strip', 'bat', 'be', 'hang', 'on', 'their', 'foot', 'for', 'best']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nltk.pos_tag(['feet']))\n",
        "#> [('feet', 'NNS')]\n",
        "\n",
        "print(nltk.pos_tag(nltk.word_tokenize(sentence)))\n",
        "#> [('The', 'DT'), ('striped', 'JJ'), ('bats', 'NNS'), ('are', 'VBP'), ('hanging', 'VBG'), ('on', 'IN'), ('their', 'PRP$'), ('feet', 'NNS'), ('for', 'IN'), ('best', 'JJS')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Awwg7E-h9kSj",
        "outputId": "123384e0-4268-4cb5-d7c8-e01e1c504661"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('feet', 'NNS')]\n",
            "[('The', 'DT'), ('striped', 'JJ'), ('bats', 'NNS'), ('are', 'VBP'), ('hanging', 'VBG'), ('on', 'IN'), ('their', 'PRP$'), ('feet', 'NNS'), ('for', 'IN'), ('best', 'JJS')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Gj-gSVaA97Zz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}